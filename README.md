# Routing_Table_RAPTOR
Artificial Intelligence analysis and chat with a Tree-Oriented Retrieval approach

## Getting started

Clone the repo

## Bring up the server
docker-compose up 

## Visit Ollama WebUI 
http://localhost:3002

## Download Your Models
Using Ollama WebUI download your model(s)

## Start Routing Table Raptor
http://localhost:8595

### Usage
This has been tested with a variety of medium to large size routing tables and works best with larger data sets. For smaller routing tables use Rout Table Buddy instead